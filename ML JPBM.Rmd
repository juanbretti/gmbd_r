---
title: "Programming R Workgroup Project: Machine Learning Model"
author: "Group E"
date: "3/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preparation

## Load libraries

```{r load_libraries, message=FALSE}
# General porpuse
library(tidyverse)
library(data.table)
library(lubridate)

# Descriptive
library(skimr)

# Visualization
library(ggplot2)

# Machine learning
library(e1071)
library(caret)

# Calculations
library(forecast)
library(mice)
library(outliers) 

# Paralel computing
library(foreach)
library(doParallel)
```

# Load data

```{r load_data}
data_solar <- readRDS(file = file.path('data', 'solar_dataset.RData'))
data_station <- fread(file = file.path('data', 'station_info.csv'))
data_add <- readRDS(file = file.path('data', 'additional_variables.RData'))
```

## Transform data

```{r}
# Source dataset
data_solar <- data_solar[j = Date2 := as.Date(x = Date, format = "%Y%m%d")]

# Add date conversions
data_solar <- data_solar %>% 
  mutate(Year = year(Date2),
         Month = month(Date2, label = TRUE),
         Day = day(Date2),
         Day_Of_Year = yday(Date2),
         Day_Of_Week = wday(Date2, label = TRUE, week_start = 1)) %>% 
  as.data.table(.)

# Columns defined from the enunciate
data_solar_col_produ <- colnames(data_solar)[2:99]
data_solar_col_predi <- colnames(data_solar)[100:456]
data_solar_col_dates <- setdiff(colnames(data_solar), c(data_solar_col_produ, data_solar_col_predi))

# Columns defined from the enunciate
data_add_col <- colnames(data_add)[2:101]
data_add_col_dates <- setdiff(colnames(data_add), data_add_col)
```

## Principal weather stations

```{r}
principal_weather_station <- data_solar_train %>% 
  pivot_longer(cols = all_of(data_solar_col_produ), names_to = 'WeatherStation', values_to = 'Value') %>% 
  group_by(WeatherStation) %>% 
  summarise(ValueSum = sum(as.numeric(Value))) %>% 
  arrange(desc(ValueSum)) %>% 
  select(WeatherStation) %>% 
  pull()
```

# Complete data_add

```{r}
data <- select(data_add, !!data_add_col)

m_ <- 1
maxit_ <- 2
data_mice_ <- mice(data, m=m_, maxit=maxit_, meth='pmm', seed=500)
saveRDS(data_mice_, file.path('storage', 'data_add_mice.rds'))
# data_mice_ <- readRDS(file.path('storage', 'data_add_mice.rds'))
# summary(data_mice_)

# Average of all the Multivariate Imputation
data_mice <- 0
for (i in 1:m_) data_mice <- data_mice + complete(data_mice_, i)
data_mice <- data_mice/m_

data_add_mice <- bind_cols(select(data_add, !!data_add_col_dates), data_mice)

# Cleanup
# rm(list = c('data', 'data_mice_', 'm_', 'maxit_', 'i', 'data_mice'))
```

# Join datasets

```{r}
data_solar_add <- data_solar %>% 
  left_join(data_add, by = 'Date', suffix = c(".solar", ".add"))
  
skim(data_solar_add)
```


```{r}

data_solar_train <- data_solar[i = 1:5113]
data_solar_test <- data_solar[i = 5114:nrow(data_solar), j = .SD, .SDcols = c(data_solar_col_dates, data_solar_col_predi)]

```



# Variable importance
## Using 'varimp'

```{r}
top_ <- 98

cl<-makeCluster(detectCores())
registerDoParallel(cl)

select_important<-function(dat, n_vars, y){
  varimp <- filterVarImp(x = dat, y=y, nonpara=TRUE)
  varimp <- data.table(variable=rownames(varimp),imp=varimp[, 1])
  varimp <- varimp[order(-imp)]
  selected <- varimp$variable[1:n_vars]
  return(selected)
}

# time_importance <- system.time({
# data_solar_importance <- foreach (x = principal_weather_station[1:top_],
#                                   .inorder=FALSE, .verbose=FALSE, .errorhandling="remove",
#                                   .packages=(.packages()), .export=ls(envir=globalenv())) %dopar% {
#                                     select_important(dat = data_solar_train[, data_solar_col_predi, with = FALSE], 
#                                                      n_vars = 50,
#                                                      y = data_solar_train[[x]])
#                                   }
# })
# print(time_importance) #1459.36
stopCluster(cl)

# saveRDS(data_solar_importance, file.path('storage', 'data_solar_importance_parallel.rds'))
data_solar_importance <- readRDS(file.path('storage', 'data_solar_importance_parallel.rds'))

names(data_solar_importance) <- principal_weather_station[1:top_]
```

## Using 'PCA'

https://topepo.github.io/caret/pre-processing.html

```{r}
pca_threshold <- 0.90
model_ <- preProcess(data_mice_, method = c("pca"), thresh = pca_threshold)
data_mice_pca <- predict(model_, data_mice_)

data_add_col_pca <- colnames(data_mice_pca)
data_add_pca <- bind_cols(data_add[, ..data_add_col_dates], data_mice_pca)
```

C:\Users\juanb\OneDrive\GMBD\STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)\Session 16 - Machine Learning\script_s16.R
C:\Users\juanb\OneDrive\GMBD\STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)\Session 17 - Forum\Ex1\Ex1 Regression.R
https://campus.ie.edu/webapps/discussionboard/do/message?action=list_messages&course_id=_114320331_1&nav=discussion_board_entry&conf_id=_251223_1&forum_id=_112829_1&message_id=_4658342_1

# Data split

```{r}
########################## [2.2.2] train/val/test split ############################

# setting seed to reproduce results of random sampling
set.seed(100) 

# row indices for training data (70%)
train_index <- sample(1:nrow(dat), 0.7*nrow(dat))  
# row indices for validation data (15%)
val_index <- sample(setdiff(1:nrow(dat), train_index), 0.15*nrow(dat))  
# row indices for test data (15%)
test_index <- setdiff(1:nrow(dat), c(train_index, val_index))

# split data
train <- dat[train_index] 
val <- dat[val_index] 
test  <- dat[test_index]
```

# Hyperparameter optimization

```{r}
########################## [2.2.3] hyperparameter optimization ############################

### Define grid
cost_values <- 10^seq(from = -2, to = 1, by = 0.5)
gamma_values <- 10^seq(from = -3, to = -1, by = 0.5)
epsilon_values <- 10^seq(from = -2, to = 0, by = 0.5)

### Compute grid search
grid_results <- data.table()

# Default values
cost <- gamma <- 1

# for (cost in cost_values) {
#   for (gamma in gamma_values) {
    for (epsilon in epsilon_values) {
    
    description <- sprintf("cost = %s, gamma = %s, epsilon = %s", cost, gamma, epsilon)
    print(description)
    
    # train SVM model with a particular set of hyperparamets
    model <- svm(mpg ~ ., data = train,
                 cost = cost, gamma = gamma, epsilon = epsilon)
    
    # Get model predictions
    predictions_train <- predict(model, newdata = train)
    predictions_val <- predict(model, newdata = val)
    
    # Get errors
    errors_train <- predictions_train - train$mpg
    errors_val <- predictions_val - val$mpg
    
    # Compute Metrics
    mse_train <- round(mean(errors_train^2), 2)
    mae_train <- round(mean(abs(errors_train)), 2)
    
    mse_val <- round(mean(errors_val^2), 2)
    mae_val <- round(mean(abs(errors_val)), 2)
    
    # Build comparison table
    grid_results <- rbind(grid_results,
                          data.table(
                            cost = cost,
                            gamma = gamma,
                            epsilon = epsilon,
                            # description = description,
                            mse_train = mse_train, 
                            mae_train = mae_train,
                            mse_val = mse_val, 
                            mae_val = mae_val))
    
    }
#   }
# }

# View results
# View(grid_results)

# Order results by increasing mse and mae
grid_results <- grid_results[order(mse_val, mae_val)]

# Check results
# View(grid_results)
# grid_results[1] # Best hyperparameters
# grid_results[which.max(mse_train)] # Underfitting! High bias-low variance (Bias-Variance tradeoff)

# Get optimized hyperparameters
best <- grid_results[1]
# best
```

# Final model
## Train

```{r}

### Train final model
# train SVM model with best found set of hyperparamets
model <- svm(mpg ~ ., data = rbind(train,val), 
             cost = best$cost, epsilon = best$epsilon, gamma = best$gamma)

# Get model predictions
predictions_train <- predict(model, newdata = train)
predictions_val <- predict(model, newdata = val)
predictions_test <- predict(model, newdata = test)

```

## Calculate errors

```{r}
# Get errors
errors_train <- predictions_train - train$mpg
errors_val <- predictions_val - val$mpg
errors_test <- predictions_test - test$mpg

# Compute Metrics
mse_train <- round(mean(errors_train^2), 2)
mae_train <- round(mean(abs(errors_train)), 2)

mse_val <- round(mean(errors_val^2), 2)
mae_val <- round(mean(abs(errors_val)), 2)

mse_test <- round(mean(errors_test^2), 2)
mae_test <- round(mean(abs(errors_test)), 2)
```
