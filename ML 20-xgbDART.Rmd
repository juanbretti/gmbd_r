  ---
title: "Programming R Workgroup Project: Machine Learning Model"
author: "Group E"
date: "3/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preparation

## Load libraries

```{r load_libraries, message=FALSE}
# General porpuse
library(tidyverse)
library(data.table)
library(lubridate)

# Descriptive
library(skimr)

# Visualization
library(ggplot2)

# Machine learning
library(xgboost)
library(caret)

# Calculations
library(mice)

# Paralel computing
library(foreach)
library(doParallel)
```

# Load data

```{r load_data}
data_solar <- readRDS(file = file.path('data', 'solar_dataset.RData'))
data_station <- fread(file = file.path('data', 'station_info.csv'))
data_add <- readRDS(file = file.path('data', 'additional_variables.RData'))
```

## Transform data

```{r}
# Source dataset
data_solar <- data_solar[j = Date2 := as.Date(x = Date, format = "%Y%m%d")]

# Add date conversions
data_solar <- data_solar %>% 
  mutate(Year = year(Date2),
         Month = month(Date2, label = TRUE),
         Day = day(Date2),
         Day_Of_Year = yday(Date2),
         Day_Of_Week = wday(Date2, label = TRUE, week_start = 1),
         Days_Since_Origin = time_length(interval(origin, Date2), unit = 'day')) %>% 
  as.data.table(.)

# Columns defined from the enunciate
data_solar_col_produ <- colnames(data_solar)[2:99]
data_solar_col_predi <- colnames(data_solar)[100:456]
data_solar_col_dates <- setdiff(colnames(data_solar), c(data_solar_col_produ, data_solar_col_predi))

# Columns defined from the enunciate
data_add_col <- colnames(data_add)[2:101]
data_add_col_dates <- setdiff(colnames(data_add), data_add_col)
```

## Complete data_add

```{r}
data <- select(data_add, !!data_add_col)

m_ <- 5
maxit_ <- 5
# data_mice_ <- mice(data, m=m_, maxit=maxit_, meth='pmm', seed=500)
# saveRDS(data_mice_, file.path('storage', 'data_add_mice.rds'))
data_mice_ <- readRDS(file.path('storage', 'data_add_mice.rds'))
# summary(data_mice_)

# Average of all the Multivariate Imputation
data_mice <- 0
for (i in 1:m_) data_mice <- data_mice + complete(data_mice_, i)
data_mice <- data_mice/m_

data_add_mice <- bind_cols(select(data_add, !!data_add_col_dates), data_mice)

# Cleanup
rm(list = c('data', 'data_mice_', 'm_', 'maxit_', 'i', 'data_mice', 'data_add'))
```

# Join datasets

```{r}
data_solar_add <- data_solar %>% 
  left_join(data_add_mice, by = 'Date', suffix = c(".solar", ".add"))

rm(list = c('data_solar', 'data_add_mice'))
# skim(data_solar_add)
```

# Train, validation, test and predict split

```{r}
data_solar_add_train_ <- data_solar_add[1:5113, ]
data_solar_add_predict <- data_solar_add[5114:nrow(data_solar_add), c(data_solar_col_dates, data_solar_col_predi, data_add_col)]

# row indices for training data (70%)
nrow_train <- round(nrow(data_solar_add_train_)*.7, 0)
# row indices for validation data (15%)
nrow_val <- round(nrow(data_solar_add_train_)*.15, 0)
# row indices for test data (15%), the reminder rows
nrow_test <- nrow(data_solar_add_train_)-nrow_train-nrow_val

data_solar_add_train <- data_solar_add_train_[1:nrow_train, ]
data_solar_add_val <- data_solar_add_train_[(nrow_train+1):(nrow_train+nrow_val), ]
data_solar_add_test <- data_solar_add_train_[(nrow_train+nrow_val+1):nrow(data_solar_add_train_), ]

rm(list=c('nrow_train', 'nrow_val', 'nrow_test', 'data_solar_add_train_', 'data_add_col_dates'))
```

# Function to add lag to the datasets

```{r}
add_lag <- function(data, n_lag=10, n_times=5, col = 'WeatherStation') {
  col_list <- NULL
  for (i in 1:n_times){
      varname <- paste(col, "lag", n_lag*i , sep="_")
      col_list <- c(col_list, varname)
      data[[varname]] <- lag(data[[col]], n_lag*i)
   }
  data <- data[((n_lag*n_times)+1):nrow(data), ]
  return(list(
    data=data,
    columns=col_list))
}
# a <-  add_lag(data_solar_add_train[1:1000, 1:4], 2, 3, 'ACME')
```

# Variable importance
Using 'filterVarImp'

```{r}
# cl<-makeCluster(detectCores())
# registerDoParallel(cl)
# 
# select_important<-function(dat, y, n_vars=ncol(dat)){
#   varimp <- filterVarImp(x = dat, y=y, nonpara=TRUE)
#   varimp <- data.table(variable=rownames(varimp),imp=varimp[, 1])
#   varimp <- varimp[order(-imp)]
#   selected <- varimp$variable[1:n_vars]
#   return(selected)
# }
# 
# time_importance <- system.time({
# data_col_importance <- foreach (x = data_solar_col_produ, .errorhandling="remove", .packages=(.packages())) %dopar% {
#                                     data <- data_solar_add_train %>% 
#                                       select(all_of(c(x, data_solar_col_predi, data_add_col))) %>% 
#                                       rename(WeatherStation = all_of(x))
#                                     data <- add_lag(data, n_lag=30, n_times=5, col='WeatherStation')
#   
#                                     out <- select_important(dat=select(data$data, all_of(c(data_solar_col_predi, data_add_col, data$columns))),
#                                                      y = data$data$WeatherStation)
#                                     return(out)
#                                     }
# })
# names(data_col_importance) <- data_solar_col_produ
# 
# # data_col_importance[2]
# print(time_importance)
# stopCluster(cl)

# saveRDS(data_col_importance, file.path('storage', 'data_col_importance3_lag.rds'))
data_col_importance <- readRDS(file.path('storage', 'data_col_importance3_lag.rds'))
# data_col_importance[1]
rm(list=c('cl', 'select_important', 'time_importance', 'data'))
```

# Hyperparameter optimization
Using caret library, for all the 'WeatherStations'
Caret
https://topepo.github.io/caret/data-splitting.html
https://topepo.github.io/caret/available-models.html
https://github.com/topepo/caret/blob/master/models/files/svmRadialSigma.R
https://github.com/topepo/caret/blob/master/models/files/xgbLinear.R
https://github.com/topepo/caret/blob/master/models/files/xgbDART.R

Others
https://xgboost.readthedocs.io/en/latest/parameter.html
https://github.com/lucaseustaquio/ams-2013-2014-solar-energy/blob/master/ams-2013-2014-R/
https://stackoverflow.com/questions/30233144/time-series-splitting-data-using-the-timeslice-method
https://robjhyndman.com/hyndsight/tscv/
http://www.quintuitive.com/2016/09/25/better-model-selection-evolving-models/
https://machinelearningmastery.com/pre-process-your-dataset-in-r/

```{r}
model_result <- function(model_train, data_train, data_val) {
  # Get model predictions
  predictions_train <- predict(model_train, newdata = data_train)
  predictions_val <- predict(model_train, newdata = data_val)
  # Get errors
  errors_train <- predictions_train - data_train$WeatherStation
  errors_val <- predictions_val - data_val$WeatherStation
  # Compute Metrics
  mse_train <- mean(errors_train^2)
  mae_train <- mean(abs(errors_train))
  mse_val <- mean(errors_val^2)
  mae_val <- mean(abs(errors_val))
  # Personal metrics
  mae_ratio = mae_val/mae_train
  fitting = ifelse(mae_ratio<1, 'Underfitting', ifelse(mae_ratio==0, 'Fit', 'Overfitting'))
  # Combining the results
  result_combined <- tibble(mse_train, mse_val, mae_train, mae_val, mae_ratio, fitting)
  # Quick plot for 'Test'
  result_plot <- ggplot() +
    geom_point(aes(y=predictions_val, x=1:nrow(data_val)), color = 'red') +
    geom_point(aes(y=data_val$WeatherStation, x=1:nrow(data_val)), color = 'blue')
  
  return(list(
    combined = result_combined,
    plot = result_plot
  ))
}

# WeatherStation <- 'ACME'
# col_importance_number <- 30

model_train <- function(WeatherStation, col_importance_number = 80) {
  
  # Columns to use, depending on the 'col_importance_number'
  col_importance <- data_col_importance[[WeatherStation]][1:col_importance_number]
  # Subset selection
  data_train <- data_solar_add_train %>% 
    rename('WeatherStation' = all_of(WeatherStation)) %>% 
    add_lag(n_lag=30, n_times=5, col='WeatherStation') %>%
    .$data %>% 
    select('WeatherStation', all_of(col_importance))
  
  data_val <- data_solar_add_val %>% 
    rename('WeatherStation' = all_of(WeatherStation)) %>% 
    add_lag(n_lag=30, n_times=5, col='WeatherStation') %>%
    .$data %>% 
    select('WeatherStation', all_of(col_importance))

  # Control
  trainControl <- trainControl(allowParallel = TRUE)
  
  # xgbDART
  tuneControl <- expand.grid(
                   nrounds = c(50, 100),
                   max_depth = c(1, 5),
                   eta = c(0.035), #0.035
                   gamma = 0,
                   subsample = c(0.4, 0.5, 0.6),
                   colsample_bytree = c(0.6, 0.8),
                   rate_drop = c(0.01, 0.30),
                   skip_drop = c(0.05, 0.95),
                   min_child_weight = 1)
  
  # Model
  train_time <- system.time({
    set.seed(42)
    model <- caret::train(WeatherStation ~ .,
                      data = data_train,
                      method = "xgbDART",
                      metric = "RMSE",
                      verbose = TRUE,
                      tuneGrid = tuneControl,
                      trControl = trainControl,
                      preProcess = c('center', 'scale'))
  })

  # Results
  model_result <- model_result(model, data_train, data_val)
  
  # To check the status
  print(paste(WeatherStation, Sys.time(), train_time[3], model_result$combined$mae_ratio, sep = ' || '))

  return(list(
    WeatherStation = WeatherStation,
    col_importance = col_importance,
    train_time = train_time,
    model = model,
    result = model_result
  ))
}

# Parallel grid search
cl<-makeCluster(detectCores())
registerDoParallel(cl)

system.time({
  model_trained <- lapply(data_solar_col_produ, model_train)
})
names(model_trained) <- data_solar_col_produ

stopCluster(cl)

saveRDS(model_trained, file.path('storage', 'model_trained_20_xgbDART.rds'))
# model_trained <- readRDS(file.path('storage', 'model_trained_20_xgbDART.rds'))

# rm(list=c('cl', 'model_train', 'model_result'))
```

## Results

```{r}
data_solar_col_produ %>% 
  map_dfr(function(x) bind_cols(WeatherStation = x, model_trained[[x]]$result$combined)) %>% 
  ggplot() + 
  geom_histogram(aes(mae_ratio, fill = fitting))
```


# Train and validation final results
Using caret library, for all the 'WeatherStations'

```{r}
model_result <- function(model_train, model_train_val, data_train, data_val, data_train_val, data_test) {
  # Get model predictions
  predictions_train <- predict(model_train, newdata = data_train)
  predictions_val <- predict(model_train, newdata = data_val)
  predictions_train_val <- predict(model_train_val, newdata = data_train_val)
  predictions_test <- predict(model_train_val, newdata = data_test)
  # Get errors
  errors_train <- predictions_train - data_train$WeatherStation
  errors_val <- predictions_val - data_val$WeatherStation
  errors_train_val <- predictions_train_val - data_train_val$WeatherStation
  errors_test <- predictions_test - data_test$WeatherStation
  # Compute Metrics
  mse_train <- mean(errors_train^2)
  mae_train <- mean(abs(errors_train))
  mse_val <- mean(errors_val^2)
  mae_val <- mean(abs(errors_val))
  mse_train_val <- mean(errors_train_val^2)
  mae_train_val <- mean(abs(errors_train_val))
  mse_test <- mean(errors_test^2)
  mae_test <- mean(abs(errors_test))
  # Personal metrics
  mae_ratio = mae_test/mae_train_val
  fitting = ifelse(mae_ratio<1, 'Underfitting', ifelse(mae_ratio==0, 'Fit', 'Overfitting'))
  # Combining the results
  result_combined <- tibble(mse_train, mse_val, mse_train_val, mse_test, mae_train, mae_val, mae_train_val, mae_test, mae_ratio, fitting)
  # Quick plot for 'Test'
  result_plot <- ggplot() +
    geom_point(aes(y=predictions_test, x=data_test$Date2), color = 'red') +
    geom_point(aes(y=data_test$WeatherStation, x=data_test$Date2), color = 'blue')
  
  return(list(
    combined = result_combined,
    plot = result_plot
  ))
}

# WeatherStation <- 'ACME'
# col_importance_number = 40
# str(trained_$model$finalModel)

model_apply <- function(WeatherStation, col_importance_number = 80) {
  
  # Final model trained
  trained_ <- model_trained[[WeatherStation]]
  
  # Columns to use, depending on the 'col_importance_number'
  col_importance <- trained_$col_importance
  
  # Subset selection
  data_train <- data_solar_add_train %>% 
    rename('WeatherStation' = all_of(WeatherStation)) %>% 
    add_lag(n_lag=30, n_times=5, col='WeatherStation') %>%
    .$data %>% 
    select('WeatherStation', all_of(col_importance))
  
  data_val <- data_solar_add_val %>% 
    rename('WeatherStation' = all_of(WeatherStation)) %>% 
    add_lag(n_lag=30, n_times=5, col='WeatherStation') %>%
    .$data %>% 
    select('WeatherStation', all_of(col_importance))
  
  data_train_val <- bind_rows(data_train, data_val)
  
  data_test <- data_solar_add_test %>% 
    rename('WeatherStation' = all_of(WeatherStation)) %>% 
    add_lag(n_lag=30, n_times=5, col='WeatherStation') %>%
    .$data %>% 
    select('WeatherStation', all_of(col_importance))
  
  # Control
  trainControl <- trainControl(allowParallel = TRUE)

  # nrounds, max_depth, eta, gamma, subsample, colsample_bytree, rate_drop, skip_drop, min_child_weight
  # Final coefficients
  # str(trained_$model$finalModel)
  model_coef <- data.frame(
    nrounds = trained_$model$finalModel$tuneValue$nrounds,
    max_depth = trained_$model$finalModel$params$max_depth,
    eta = trained_$model$finalModel$params$eta,
    gamma = trained_$model$finalModel$params$gamma,
    subsample = trained_$model$finalModel$params$subsample,
    colsample_bytree = trained_$model$finalModel$params$colsample_bytree,
    rate_drop = trained_$model$finalModel$tuneValue$rate_drop,
    skip_drop = trained_$model$finalModel$tuneValue$skip_drop,
    min_child_weight = trained_$model$finalModel$tuneValue$min_child_weight
  )
  
  # Model
  train_time <- system.time({
    set.seed(42)
    model <- caret::train(WeatherStation ~ .,
                      data = data_train_val,
                      method = "xgbDART",
                      metric = "RMSE",
                      tuneGrid = model_coef,
                      trControl = trainControl,
                      preProcess = c('center', 'scale'))
  })
  
  # Results
  model_result <- model_result(trained_$model, model, data_train, data_val, data_train_val, data_test)

    # To check the status
  print(paste(WeatherStation, Sys.time(), train_time[3], model_result$combined$mae_ratio, sep = ' || '))

  return(list(
    WeatherStation = WeatherStation,
    train_time = train_time,
    model = model,
    result = model_result
  ))
}

# Parallel apply
cl<-makeCluster(detectCores())
registerDoParallel(cl)

system.time({
  model_applied <- lapply(data_solar_col_produ, model_apply)
})
names(model_applied) <- data_solar_col_produ

stopCluster(cl)

saveRDS(model_applied, file.path('storage', 'model_applied_20_xgb.rds'))
# model_applied <- readRDS(file.path('storage', 'model_applied_20_xgb.rds'))

rm(list=c('cl', 'model_apply', 'model_result'))
```

## Results

```{r}
data_solar_col_produ %>% 
  map_dfr(function(x) bind_cols(WeatherStation = x, model_applied[[x]]$result$combined)) %>% 
  ggplot() + 
  geom_histogram(aes(mae_ratio, fill = fitting))
```

# Submission File
Submission: https://www.kaggle.com/c/ams-2014-solar-energy-prediction-contest/submit
Leaderboard: https://www.kaggle.com/c/ams-2014-solar-energy-prediction-contest/leaderboard#score
Jesús: https://campus.ie.edu/webapps/discussionboard/do/message?action=list_messages&course_id=_114320331_1&nav=discussion_board_entry&conf_id=_251223_1&forum_id=_112829_1&message_id=_4658342_1

```{r}
# data_solar_add_train_ <- data_solar_add[1:5113, ]
# data_solar_add_predict <- data_solar_add[5114:nrow(data_solar_add), c(data_solar_col_dates, data_solar_col_predi, data_add_col)]


# row_to_predict <- 5114
# WeatherStation <- 'ACME'

predict_fun <- function(row_to_predict, WeatherStation) {

  rows_lag <- 30*5 #n_lag * n_times
  subset_to_predict <- data[(row_to_predict-rows_lag):row_to_predict, ]
  
  col_importance <- model_trained[[WeatherStation]]$col_importance
  
  data_predict <- subset_to_predict %>% 
    rename('WeatherStation' = all_of(WeatherStation)) %>% 
    add_lag(n_lag=30, n_times=5, col='WeatherStation') %>%
    .$data %>% 
    select(all_of(col_importance))
  
  value_predicted <- predict(object = model_applied[[WeatherStation]]$model, newdata = data_predict)
  data[row_to_predict, WeatherStation] <<- value_predicted

  return(list(
    value_predicted = value_predicted,
    data = data
  ))
  
}

# Test
# row_ <- 5123
# predict_fun(row_, 'ACME')$value_predicted
# predict_fun(row_, 'ACME')$data[row_, 'ACME']
# data[row_, 'ACME']

system.time({
  data <- data_solar_add
  for (ws_ in data_solar_col_produ) {
    print(paste(ws_, Sys.time(), sep = ' || '))
    for (row_ in 5114:nrow(data_solar_add)) {
      predict_fun(row_, ws_)  
    }
  }
})

out <- data %>% 
  select('Date', all_of(data_solar_col_produ)) %>% 
  slice(5114:n())

saveRDS(out, file.path('storage', 'out_20_xgb.rds'))
# out <- readRDS(file.path('storage', 'out_20_xgb.rds'))

write.table(x = out, file = file.path('storage', 'out.csv'), sep = ',', dec = '.', row.names = FALSE, quote = FALSE)
# 
# rm(list=c('predict_fun', 'out', 'data'))
```

